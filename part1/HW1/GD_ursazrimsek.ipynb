{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem 5\n",
    "\n",
    "Projections from problem 3.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def projectionA(X):\n",
    "    x, y = X\n",
    "    if x**2 + y**2 <= 1.5:\n",
    "        return x, y\n",
    "    else:\n",
    "        return np.sqrt(1.5 / (x**2 + y**2)) * np.array([x, y])\n",
    "\n",
    "\n",
    "def projectionB(X):\n",
    "    x, y = X\n",
    "    return np.array([projectionB1(x), projectionB1(y)])\n",
    "\n",
    "\n",
    "def projectionB1(x):\n",
    "    if x < -1:\n",
    "        return -1\n",
    "    elif x > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def projectionC(X):\n",
    "    x, y = X\n",
    "    if -1 <= x <= 1.5 and -1 <= y <= 1.5 and y <= 0.5 - x:\n",
    "        return np.array([x, y])\n",
    "    if x < -1:\n",
    "        if y < -1:\n",
    "            return np.array([-1, -1])\n",
    "        elif y < 1.5:\n",
    "            return np.array([-1, y])\n",
    "        else:\n",
    "            return np.array([-1, 1.5])\n",
    "    elif y < -1:\n",
    "        if x < 1.5:\n",
    "            return np.array([x, -1])\n",
    "        else:\n",
    "            return np.array([1.5, -1])\n",
    "    elif y > 2.5 + x:\n",
    "        return np.array([-1, 1.5])\n",
    "    elif x > 2.5 + y:\n",
    "        return np.array([1.5, -1])\n",
    "    else:\n",
    "        return np.array([(0.5 - y + x) / 2, (0.5 - x + y) / 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Function from problem 2. and its gradient, projected gradient descent to find its minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    x, y = X\n",
    "    return x**2 + np.exp(x) + y**2 - x*y\n",
    "\n",
    "\n",
    "def gradf(X):\n",
    "    x, y = X\n",
    "    return np.array([2*x + np.exp(x) - y, 2*y - x])\n",
    "\n",
    "\n",
    "def proj_gd_step(X, projection, learning_rate):\n",
    "    # print(f'point: {X - learning_rate*(gradf(X))}')\n",
    "    # print(projection(X - learning_rate*(gradf(X))))\n",
    "    return projection(X - learning_rate*(gradf(X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters for gradient descents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_1 = np.array([-1, 1])\n",
    "actual_min = np.array([-0.43256275, -0.43256275/2])\n",
    "\n",
    "L = np.sqrt(72 + 12*np.exp(2) + np.exp(4))\n",
    "beta = (4 + np.exp(2) + np.sqrt(4 + np.exp(4))) / 2\n",
    "alpha = (4 + np.exp(-2) - np.sqrt(4 + np.exp(-4))) / 2\n",
    "\n",
    "T = 11                                                              # we are doing 10 steps -> we have 11 points\n",
    "dist_x1_act = np.linalg.norm(X_1 - actual_min)\n",
    "\n",
    "learning_rates = [dist_x1_act / (L*np.sqrt(T)), 1/beta, 2/alpha]    # 1., 2. and 3., 4. inequality\n",
    "projections = [projectionA, projectionB, projectionC]               # circle, square, triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027581075359712888, 0.1050199595887474, 1.877263037818603]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 4-dim array ```points``` we will save all the points from gradient descends with different learning rates and domains for projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.zeros([3, 3, 11, 2])     # projections, learning_rates, iterations, x/y\n",
    "points[:, :, 0, :] = X_1\n",
    "\n",
    "for p in range(len(projections)):\n",
    "    for l in range(len(learning_rates)):\n",
    "        for k in range(1, T):\n",
    "            lr = learning_rates[l]\n",
    "            if l == 2:\n",
    "                lr = lr / (k+1)\n",
    "            points[p, l, k, :] = proj_gd_step(points[p, l, k-1, :], projections[p], lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00257168, 0.00831117, 0.01194306])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(points[:, 2, -1, :] - actual_min, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons from Theorem 3.3. In 3 dimensional array ```ineq``` we have 4 inequalities (first index) for projections on 3 different domains (second index). In third dimension we saved the values of left (0) and right (1) side of inequality. The right side is the same for all the projections, since it is only dependand on starting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineq = np.zeros([4, 3, 2])          # inequality, domain, left/right side\n",
    "for p in range(len(projections)):\n",
    "    ineq[0, p, :] = [f(sum(points[p, 0, :, :])/T) - f(actual_min), L*dist_x1_act/np.sqrt(T)]\n",
    "    ineq[1, p, :] = [f(points[p, 1, -1, :]) - f(actual_min), (3*beta*dist_x1_act**2 + f(X_1) - f(actual_min)) / T]\n",
    "    kappa = beta/alpha\n",
    "    ineq[2, p, :] = [f(points[p, 1, -1, :]) - f(actual_min), beta/2 * ((kappa-1)/kappa)**(2*(T-1))*dist_x1_act**2]\n",
    "    ineq[3, p, :] = [f(2/(T*(T+1))*np.matmul(np.array(range(1, 12)), points[p, 2, :, :])) - f(actual_min),\n",
    "                    2*L**2/(alpha*(T+1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.03227949e+00, 5.93729047e+00],\n",
       "        [1.15791251e+00, 5.93729047e+00],\n",
       "        [1.15791251e+00, 5.93729047e+00]],\n",
       "\n",
       "       [[1.51814100e-02, 4.91230558e+00],\n",
       "        [1.51814100e-02, 4.91230558e+00],\n",
       "        [1.51814100e-02, 4.91230558e+00]],\n",
       "\n",
       "       [[1.51814100e-02, 7.99212423e-01],\n",
       "        [1.51814100e-02, 7.99212423e-01],\n",
       "        [1.51814100e-02, 7.99212423e-01]],\n",
       "\n",
       "       [[6.25513352e-05, 3.36760375e+01],\n",
       "        [3.36122482e-03, 3.36760375e+01],\n",
       "        [7.30601333e-03, 3.36760375e+01]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First inequality\n",
    "The upper bound here is equal to *5.93729047*, below are the values of the left side for each domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle: 1.0322794917332974, square: 1.1579125074614298, triangle: 1.1579125074614298\n"
     ]
    }
   ],
   "source": [
    "print(f'Circle: {ineq[0,0,0]}, square: {ineq[0,1,0]}, triangle: {ineq[0,2,0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second inequality\n",
    "Here we took ```k=11```, to compare the value of f at the point from last step of our gradient descent with value of f at real minimum.\n",
    "The upper bound here is equal to *4.91230558*, below are the values of the left side for each domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle: 0.015181409998737405, square: 0.015181409998737405, triangle: 0.015181409998737405\n"
     ]
    }
   ],
   "source": [
    "print(f'Circle: {ineq[1,0,0]}, square: {ineq[1,1,0]}, triangle: {ineq[1,2,0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third inequality\n",
    "In this inequality we took ```k=10```, to again compare value of f in the last point we calculated with 10 steps (so these values are the same as in second inequality).\n",
    "The upper bound here is equal to *0.799212423*, below are the values of the left side for each domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle: 0.015181409998737405, square: 0.015181409998737405, triangle: 0.015181409998737405\n"
     ]
    }
   ],
   "source": [
    "print(f'Circle: {ineq[2,0,0]}, square: {ineq[2,1,0]}, triangle: {ineq[2,2,0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth inequality\n",
    "\n",
    "The upper bound here is equal to *33.6760375*, below are the values of the left side for each domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle: 6.255133523047629e-05, square: 0.003361224817534092, triangle: 0.007306013330456884\n"
     ]
    }
   ],
   "source": [
    "print(f'Circle: {ineq[3,0,0]}, square: {ineq[3,1,0]}, triangle: {ineq[3,2,0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that all of the guarantees hold, but some of them are more precise than others. Since second and third are guarantees for the same value, we can conclude that the third one is much better for this example, since it is more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the results\n",
    "We will look at how far the final points of gradient descend are from the actual minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6049279 , 0.15288255, 0.00257168],\n",
       "       [0.63381875, 0.15288255, 0.00831117],\n",
       "       [0.63381875, 0.15288255, 0.01194306]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(points[:, :, -1, :] - actual_min, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the results for different learning rates (columns) when we are projecting on different sets (rows: circle, square, triangle). We can see that the best learning rate in all cases is the last one, which is changing in each iteration: 2/(alpha* (k+1))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[3, 10, 30],[0.1, 10, 35],[3, 10, 30],[0.1, 10, 35]])\n",
    "c = np.array([1, 1.2, 3, 3.2])\n",
    "p = np.array([[0.36890, 0.1170, 0.2673], [0.46990, 0.4387, 0.7470], [0.10910, 0.8732, 0.5547], [0.03815, 0.5743, 0.8828]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f6(z):\n",
    "    result = 0\n",
    "    for i in range(4):\n",
    "        ex = 0\n",
    "        for j in range(3):\n",
    "            ex -= a[i, j] * (z[j] - p[i, j])**2\n",
    "        result -= c[i] * np.exp(ex)\n",
    "    return result\n",
    "        \n",
    "def gradf6(z):\n",
    "    result = [0, 0, 0]\n",
    "    for i in range(4):\n",
    "        ex = 0\n",
    "        for j in range(3):\n",
    "            ex -= a[i, j] * (z[j] - p[i, j])**2\n",
    "        for k in range(3):\n",
    "            result[k] += c[i] * np.exp(ex) * 2 * a[i, k] * (z[k] - p[i, k])\n",
    "    return np.array(result)\n",
    "\n",
    "def p_GD_step(X, learning_rate, projection=lambda x: x):\n",
    "    return projection(X - learning_rate*(gradf6(X)))\n",
    "\n",
    "def p_GD(X, n_steps, learning_rate, projection=lambda x: x):\n",
    "    points = [X]\n",
    "    for i in range(n_steps):\n",
    "        points.append(p_GD_step(points[-1], learning_rate, projection))\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.10421470e-78, 9.04795039e-76, 4.70275110e-75])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradf6([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8627821477879825"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f6(p_GD(np.array([1,1,1]), 1000, 0.01)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 1e-14 in 1359 steps.\n",
      "Reached 0.5e-14 in 8373 steps.\n",
      "Reached 0.4e-14 in 20847 steps.\n"
     ]
    }
   ],
   "source": [
    "start = [1,1,1]\n",
    "steps = 0\n",
    "minimal_value = -3.86278214782076\n",
    "lr = 0.01\n",
    "x = start\n",
    "while f6(x) - minimal_value > 1e-14:\n",
    "    x = p_GD_step(x, lr)\n",
    "    steps += 1\n",
    "\n",
    "print(f'Reached 1e-14 in {steps} steps.')\n",
    "while f6(x) - minimal_value > 0.5e-14:\n",
    "    x = p_GD_step(x, lr/100)\n",
    "    steps += 1\n",
    "print(f'Reached 0.5e-14 in {steps} steps.')\n",
    "while f6(x) - minimal_value > 0.4e-14:\n",
    "    x = p_GD_step(x, lr/100)\n",
    "    steps += 1\n",
    "print(f'Reached 0.4e-14 in {steps} steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With learning rate 0.01 we reach smaller difference than 1e-14: 9.769962616701378e-15 in 1359 steps.\n"
     ]
    }
   ],
   "source": [
    "print(f'With learning rate 0.01 we reach smaller difference than 1e-14: {abs(f6(x) - minimal_value)} in {steps} steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With learning rate 0.001 we reach smaller difference than 1e-14: 9.769962616701378e-15 in 13638 steps\n"
     ]
    }
   ],
   "source": [
    "print(f'With learning rate 0.001 we reach smaller difference than 1e-14: {abs(f6(x) - minimal_value)} in {steps} steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With learning rate 0.0001 we reach smaller difference than 1e-14: 9.769962616701378e-15 in 136294 steps\n"
     ]
    }
   ],
   "source": [
    "print(f'With learning rate 0.0001 we reach smaller difference than 1e-14: {abs(f6(x) - minimal_value)} in {steps} steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With learning rate 0.01 for first 1359 and then 0.0001, we reach difference of 3.9968028886505635e-15 in 20847 steps\n"
     ]
    }
   ],
   "source": [
    "print(f'With learning rate 0.01 for first 1359 and then 0.0001, we reach difference of {abs(f6(x) - minimal_value)} in {steps} steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f6(x): -3.862782147820756\n"
     ]
    }
   ],
   "source": [
    "print(f'Value of f6(x): {f6(x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now we have reached the value that rounds to given minimal value of f."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MAT2]",
   "language": "python",
   "name": "conda-env-MAT2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
